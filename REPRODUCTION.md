# MedicalGPT é¡¹ç›®å¤ç°æ•™ç¨‹

æœ¬æ–‡æ¡£æä¾›è¯¦ç»†çš„ MedicalGPT é¡¹ç›®å¤ç°æ­¥éª¤ï¼Œå¸®åŠ©æ‚¨ä»é›¶å¼€å§‹å®Œæˆç¯å¢ƒæ­å»ºã€æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†éƒ¨ç½²çš„å…¨æµç¨‹ã€‚

## ğŸ“‹ ç›®å½•

- [1. ç¯å¢ƒå‡†å¤‡](#1-ç¯å¢ƒå‡†å¤‡)
- [2. æ•°æ®å‡†å¤‡](#2-æ•°æ®å‡†å¤‡)
- [3. æ¨¡å‹å‡†å¤‡](#3-æ¨¡å‹å‡†å¤‡)
- [4. è®­ç»ƒæµç¨‹](#4-è®­ç»ƒæµç¨‹)
  - [4.1 é˜¶æ®µä¸€ï¼šå¢é‡é¢„è®­ç»ƒ (PT)](#41-é˜¶æ®µä¸€å¢é‡é¢„è®­ç»ƒ-pt)
  - [4.2 é˜¶æ®µäºŒï¼šæœ‰ç›‘ç£å¾®è°ƒ (SFT)](#42-é˜¶æ®µäºŒæœ‰ç›‘ç£å¾®è°ƒ-sft)
  - [4.3 é˜¶æ®µä¸‰ï¼šå¥–åŠ±å»ºæ¨¡ (RM)](#43-é˜¶æ®µä¸‰å¥–åŠ±å»ºæ¨¡-rm)
  - [4.4 é˜¶æ®µå››ï¼šå¼ºåŒ–å­¦ä¹ è®­ç»ƒ](#44-é˜¶æ®µå››å¼ºåŒ–å­¦ä¹ è®­ç»ƒ)
  - [4.5 é˜¶æ®µä¸‰æ›¿ä»£æ–¹æ¡ˆï¼šDPOè®­ç»ƒ](#45-é˜¶æ®µä¸‰æ›¿ä»£æ–¹æ¡ˆdpoè®­ç»ƒ)
  - [4.6 é˜¶æ®µä¸‰æ›¿ä»£æ–¹æ¡ˆï¼šORPOè®­ç»ƒ](#46-é˜¶æ®µä¸‰æ›¿ä»£æ–¹æ¡ˆorpoè®­ç»ƒ)
- [5. æ¨¡å‹æ¨ç†](#5-æ¨¡å‹æ¨ç†)
- [6. æ¨¡å‹éƒ¨ç½²](#6-æ¨¡å‹éƒ¨ç½²)
- [7. å¸¸è§é—®é¢˜](#7-å¸¸è§é—®é¢˜)
- [8. èµ„æºéœ€æ±‚](#8-èµ„æºéœ€æ±‚)

---

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (æ¨è Ubuntu 20.04+)
- **Python**: 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- **CUDA**: 11.8 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆGPUè®­ç»ƒå¿…éœ€ï¼‰
- **æ˜¾å­˜**: æ ¹æ®æ¨¡å‹å¤§å°å’Œè®­ç»ƒæ–¹æ³•ï¼Œè‡³å°‘éœ€è¦ 6GBï¼ˆQLoRA 4bit è®­ç»ƒ 7B æ¨¡å‹ï¼‰

### 1.2 å…‹éš†é¡¹ç›®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/shibing624/MedicalGPT.git
cd MedicalGPT
```

### 1.3 å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
# venv\Scripts\activate  # Windows

# å®‰è£… PyTorchï¼ˆæ ¹æ®æ‚¨çš„ CUDA ç‰ˆæœ¬é€‰æ‹©ï¼‰
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt --upgrade
```

### 1.4 éªŒè¯å®‰è£…

```bash
# éªŒè¯å…³é”®åº“æ˜¯å¦æ­£ç¡®å®‰è£…
python -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')"
python -c "import transformers; print(f'Transformersç‰ˆæœ¬: {transformers.__version__}')"
python -c "import peft; print(f'PEFTç‰ˆæœ¬: {peft.__version__}')"
python -c "import trl; print(f'TRLç‰ˆæœ¬: {trl.__version__}')"
```

---

## 2. æ•°æ®å‡†å¤‡

### 2.1 æ•°æ®ç›®å½•ç»“æ„

åˆ›å»ºæ•°æ®ç›®å½•å¹¶å‡†å¤‡æ•°æ®æ–‡ä»¶ï¼š

```bash
mkdir -p data/pretrain   # é¢„è®­ç»ƒæ•°æ®
mkdir -p data/finetune  # å¾®è°ƒæ•°æ®
mkdir -p data/reward    # å¥–åŠ±æ¨¡å‹æ•°æ®ï¼ˆåå¥½æ•°æ®ï¼‰
```

### 2.2 é¢„è®­ç»ƒæ•°æ®æ ¼å¼

é¢„è®­ç»ƒæ•°æ®åº”ä¸ºçº¯æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªæ–‡æ¡£ã€‚ç¤ºä¾‹ï¼š

```
è¿™æ˜¯ç¬¬ä¸€ä¸ªåŒ»ç–—æ–‡æ¡£çš„å†…å®¹...
è¿™æ˜¯ç¬¬äºŒä¸ªåŒ»ç–—æ–‡æ¡£çš„å†…å®¹...
```

### 2.3 å¾®è°ƒæ•°æ®æ ¼å¼

å¾®è°ƒæ•°æ®æ”¯æŒå¤šç§æ ¼å¼ï¼Œæ¨èä½¿ç”¨ JSONL æ ¼å¼ï¼ˆShareGPT æ ¼å¼ï¼‰ï¼š

**å•è½®å¯¹è¯æ ¼å¼** (`alpaca` æ¨¡æ¿):
```json
{"instruction": "å°å­©å‘çƒ§æ€ä¹ˆåŠ", "input": "", "output": "å‘çƒ§æ˜¯èº«ä½“å¯¹æ„ŸæŸ“çš„ååº”..."}
{"instruction": "å¦‚ä½•é¢„é˜²æ„Ÿå†’", "input": "", "output": "é¢„é˜²æ„Ÿå†’çš„æ–¹æ³•åŒ…æ‹¬..."}
```

**å¤šè½®å¯¹è¯æ ¼å¼** (`sharegpt`/`vicuna` æ¨¡æ¿):
```json
{"conversations": [{"from": "human", "value": "ä½ å¥½"}, {"from": "gpt", "value": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}]}
{"conversations": [{"from": "human", "value": "æ„Ÿå†’äº†æ€ä¹ˆåŠ"}, {"from": "gpt", "value": "æ„Ÿå†’æ—¶åº”è¯¥..."}]}
```

### 2.4 å¥–åŠ±æ¨¡å‹æ•°æ®æ ¼å¼ï¼ˆåå¥½æ•°æ®ï¼‰

DPO/RM è®­ç»ƒéœ€è¦åå¥½æ•°æ®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```json
{"prompt": "å°å­©å‘çƒ§æ€ä¹ˆåŠ", "chosen": "æ­£ç¡®çš„å›ç­”...", "rejected": "ä¸æ­£ç¡®çš„å›ç­”..."}
{"prompt": "å¦‚ä½•é¢„é˜²æ„Ÿå†’", "chosen": "å¥½çš„å›ç­”...", "rejected": "ä¸å¥½çš„å›ç­”..."}
```

### 2.5 æ•°æ®é›†ä¸‹è½½

#### åŒ»ç–—æ•°æ®é›†
- 240ä¸‡æ¡ä¸­æ–‡åŒ»ç–—æ•°æ®é›†: [shibing624/medical](https://huggingface.co/datasets/shibing624/medical)
- 22ä¸‡æ¡ä¸­æ–‡åŒ»ç–—å¯¹è¯æ•°æ®é›†: [shibing624/huatuo_medical_qa_sharegpt](https://huggingface.co/datasets/shibing624/huatuo_medical_qa_sharegpt)

#### é€šç”¨æ•°æ®é›†
- 10ä¸‡æ¡å¤šè¯­è¨€ShareGPT GPT4å¤šè½®å¯¹è¯: [shibing624/sharegpt_gpt4](https://huggingface.co/datasets/shibing624/sharegpt_gpt4)
- 2ä¸‡æ¡ä¸­è‹±æ–‡åå¥½æ•°æ®é›†: [shibing624/DPO-En-Zh-20k-Preference](https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference)

ä½¿ç”¨ Hugging Face datasets ä¸‹è½½ï¼š

```python
from datasets import load_dataset

# ä¸‹è½½åŒ»ç–—æ•°æ®é›†
dataset = load_dataset("shibing624/medical")
dataset.save_to_disk("./data/medical")

# ä¸‹è½½åå¥½æ•°æ®é›†
pref_dataset = load_dataset("shibing624/DPO-En-Zh-20k-Preference")
pref_dataset.save_to_disk("./data/reward")
```

---

## 3. æ¨¡å‹å‡†å¤‡

### 3.1 é€‰æ‹©åŸºç¡€æ¨¡å‹

æ ¹æ®ç¡¬ä»¶èµ„æºé€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š

| æ¨¡å‹ç³»åˆ— | æ¨èæ¨¡å‹ | æ˜¾å­˜éœ€æ±‚ (QLoRA 4bit) | è¯´æ˜ |
|---------|---------|---------------------|------|
| Qwen2.5 | Qwen2.5-0.5B/1.5B/7B | 6GB/8GB/16GB | æ¨èï¼Œä¸­æ–‡æ”¯æŒå¥½ |
| Qwen2 | Qwen2-7B | 16GB | æ€§èƒ½ä¼˜ç§€ |
| LLaMA3 | Llama-3-8B | 20GB | å¼€æºç¤¾åŒºå¹¿æ³›ä½¿ç”¨ |
| LLaMA2 | Llama-2-7B-chat | 16GB | ç»å…¸é€‰æ‹© |

### 3.2 ä¸‹è½½æ¨¡å‹

ä½¿ç”¨ Hugging Face Hub ä¸‹è½½æ¨¡å‹ï¼š

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "Qwen/Qwen2.5-0.5B-Instruct"  # ç¤ºä¾‹ï¼Œæ ¹æ®éœ€æ±‚é€‰æ‹©
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# æˆ–ä½¿ç”¨å‘½ä»¤è¡Œ
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir ./models/Qwen2.5-0.5B-Instruct
```

### 3.3 æ¨¡å‹è·¯å¾„é…ç½®

åœ¨è®­ç»ƒè„šæœ¬ä¸­ï¼Œå°†æ¨¡å‹è·¯å¾„è®¾ç½®ä¸ºï¼š

```bash
--model_name_or_path Qwen/Qwen2.5-0.5B-Instruct  # ä½¿ç”¨ Hugging Face Hub åç§°
# æˆ–
--model_name_or_path ./models/Qwen2.5-0.5B-Instruct  # ä½¿ç”¨æœ¬åœ°è·¯å¾„
```

---

## 4. è®­ç»ƒæµç¨‹

MedicalGPT æä¾›å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©ä¸åŒçš„é˜¶æ®µç»„åˆã€‚

### 4.1 é˜¶æ®µä¸€ï¼šå¢é‡é¢„è®­ç»ƒ (PT)

**ç›®çš„**: åœ¨é¢†åŸŸæ–‡æ¡£ä¸Šç»§ç»­é¢„è®­ç»ƒï¼Œæ³¨å…¥é¢†åŸŸçŸ¥è¯†ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰

**æ•°æ®**: `./data/pretrain` ç›®å½•ä¸‹çš„çº¯æ–‡æœ¬æ–‡ä»¶

**è®­ç»ƒå‘½ä»¤**:

```bash
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node 2 pretraining.py \
    --model_name_or_path Qwen/Qwen2.5-0.5B \
    --train_file_dir ./data/pretrain \
    --validation_file_dir ./data/pretrain \
    --per_device_train_batch_size 4 \
    --per_device_eval_batch_size 4 \
    --do_train \
    --do_eval \
    --use_peft True \
    --seed 42 \
    --max_train_samples 10000 \
    --max_eval_samples 10 \
    --num_train_epochs 0.5 \
    --learning_rate 2e-4 \
    --warmup_ratio 0.05 \
    --weight_decay 0.01 \
    --logging_strategy steps \
    --logging_steps 10 \
    --eval_steps 50 \
    --eval_strategy steps \
    --save_steps 500 \
    --save_strategy steps \
    --save_total_limit 13 \
    --gradient_accumulation_steps 8 \
    --preprocessing_num_workers 10 \
    --block_size 512 \
    --group_by_length True \
    --output_dir outputs-pt-qwen-v1 \
    --overwrite_output_dir \
    --ddp_timeout 30000 \
    --logging_first_step True \
    --target_modules all \
    --lora_rank 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --torch_dtype bfloat16 \
    --bf16 \
    --device_map auto \
    --report_to tensorboard \
    --ddp_find_unused_parameters False \
    --gradient_checkpointing True \
    --cache_dir ./cache
```

**å…³é”®å‚æ•°è¯´æ˜**:
- `--model_name_or_path`: åŸºç¡€æ¨¡å‹è·¯å¾„
- `--train_file_dir`: è®­ç»ƒæ•°æ®ç›®å½•
- `--use_peft True`: ä½¿ç”¨ LoRA å¾®è°ƒï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
- `--lora_rank 8`: LoRA ç§©å¤§å°
- `--output_dir`: æ¨¡å‹è¾“å‡ºç›®å½•

**è¾“å‡º**: `outputs-pt-qwen-v1` ç›®å½•ä¸‹çš„ LoRA æƒé‡

**æ˜¾å­˜éœ€æ±‚**: 
- QLoRA 4bit: çº¦ 6-8GB (7B æ¨¡å‹)
- LoRA 16bit: çº¦ 16GB (7B æ¨¡å‹)

---

### 4.2 é˜¶æ®µäºŒï¼šæœ‰ç›‘ç£å¾®è°ƒ (SFT)

**ç›®çš„**: åœ¨æŒ‡ä»¤æ•°æ®ä¸Šå¾®è°ƒï¼Œå¯¹é½æŒ‡ä»¤æ„å›¾ï¼ˆå¿…éœ€ï¼‰

**æ•°æ®**: `./data/finetune` ç›®å½•ä¸‹çš„ JSONL æ ¼å¼æ–‡ä»¶

**è®­ç»ƒå‘½ä»¤**:

```bash
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node 2 supervised_finetuning.py \
    --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --train_file_dir ./data/finetune \
    --validation_file_dir ./data/finetune \
    --per_device_train_batch_size 4 \
    --per_device_eval_batch_size 4 \
    --do_train \
    --do_eval \
    --template_name qwen \
    --use_peft True \
    --max_train_samples 1000 \
    --max_eval_samples 10 \
    --model_max_length 4096 \
    --num_train_epochs 1 \
    --learning_rate 2e-5 \
    --warmup_ratio 0.05 \
    --weight_decay 0.05 \
    --logging_strategy steps \
    --logging_steps 10 \
    --eval_steps 50 \
    --eval_strategy steps \
    --save_steps 500 \
    --save_strategy steps \
    --save_total_limit 13 \
    --gradient_accumulation_steps 8 \
    --preprocessing_num_workers 4 \
    --output_dir outputs-sft-qwen-v1 \
    --overwrite_output_dir \
    --ddp_timeout 30000 \
    --logging_first_step True \
    --target_modules all \
    --lora_rank 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --torch_dtype bfloat16 \
    --bf16 \
    --device_map auto \
    --report_to tensorboard \
    --ddp_find_unused_parameters False \
    --gradient_checkpointing True \
    --cache_dir ./cache \
    --flash_attn True
```

**å…³é”®å‚æ•°è¯´æ˜**:
- `--template_name`: å¯¹è¯æ¨¡æ¿åç§°ï¼ˆå¦‚ `qwen`, `vicuna`, `alpaca`ï¼‰
- `--model_max_length`: æœ€å¤§åºåˆ—é•¿åº¦
- `--flash_attn`: æ˜¯å¦ä½¿ç”¨ Flash Attentionï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰

**å¦‚æœä½¿ç”¨ PT é˜¶æ®µçš„è¾“å‡º**:

```bash
# éœ€è¦å…ˆåˆå¹¶ PT é˜¶æ®µçš„ LoRA æƒé‡
python merge_peft_adapter.py \
    --base_model_name_or_path Qwen/Qwen2.5-0.5B \
    --peft_model_path outputs-pt-qwen-v1/checkpoint-500 \
    --output_dir merged-pt-qwen-v1

# ç„¶ååœ¨ SFT æ—¶ä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹
--model_name_or_path merged-pt-qwen-v1
```

**è¾“å‡º**: `outputs-sft-qwen-v1` ç›®å½•ä¸‹çš„ LoRA æƒé‡

---

### 4.3 é˜¶æ®µä¸‰ï¼šå¥–åŠ±å»ºæ¨¡ (RM)

**ç›®çš„**: è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œå»ºæ¨¡äººç±»åå¥½ï¼ˆRLHF æµç¨‹å¿…éœ€ï¼‰

**æ•°æ®**: `./data/reward` ç›®å½•ä¸‹çš„åå¥½æ•°æ®ï¼ˆchosen/rejected æ ¼å¼ï¼‰

**è®­ç»ƒå‘½ä»¤**:

```bash
# æ³¨æ„ï¼šreward model è®­ç»ƒæš‚ä¸æ”¯æŒ torchrun å¤šå¡è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1 python reward_modeling.py \
    --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --train_file_dir ./data/reward \
    --validation_file_dir ./data/reward \
    --per_device_train_batch_size 4 \
    --gradient_accumulation_steps 8 \
    --per_device_eval_batch_size 4 \
    --do_train \
    --use_peft True \
    --seed 42 \
    --max_train_samples 1000 \
    --max_eval_samples 10 \
    --num_train_epochs 1 \
    --learning_rate 2e-5 \
    --warmup_ratio 0.05 \
    --weight_decay 0.001 \
    --logging_strategy steps \
    --logging_steps 10 \
    --eval_steps 50 \
    --eval_strategy steps \
    --save_steps 500 \
    --save_strategy steps \
    --save_total_limit 3 \
    --max_source_length 1024 \
    --max_target_length 256 \
    --output_dir outputs-rm-qwen-v1 \
    --overwrite_output_dir \
    --ddp_timeout 30000 \
    --logging_first_step True \
    --target_modules all \
    --lora_rank 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --bf16 \
    --torch_dtype bfloat16 \
    --device_map auto \
    --report_to tensorboard \
    --ddp_find_unused_parameters False \
    --remove_unused_columns False \
    --gradient_checkpointing True
```

**è¾“å‡º**: `outputs-rm-qwen-v1` ç›®å½•ä¸‹çš„å¥–åŠ±æ¨¡å‹æƒé‡

---

### 4.4 é˜¶æ®µå››ï¼šå¼ºåŒ–å­¦ä¹ è®­ç»ƒ (PPO)

**ç›®çš„**: ä½¿ç”¨å¥–åŠ±æ¨¡å‹ä¼˜åŒ–ç”Ÿæˆç­–ç•¥ï¼ˆRLHF æµç¨‹çš„æœ€åä¸€æ­¥ï¼‰

**è®­ç»ƒå‘½ä»¤**:

```bash
CUDA_VISIBLE_DEVICES=0,1 python ppo_training.py \
    --sft_model_path outputs-sft-qwen-v1/checkpoint-500 \
    --reward_model_path outputs-rm-qwen-v1/checkpoint-500 \
    --template_name qwen \
    --torch_dtype bfloat16 \
    --train_file_dir ./data/finetune \
    --validation_file_dir ./data/finetune \
    --max_source_length 1024 \
    --response_length 1000 \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 4 \
    --gradient_checkpointing True \
    --do_train \
    --total_episodes 30000 \
    --output_dir outputs-ppo-qwen-v1 \
    --missing_eos_penalty 1.0 \
    --eval_strategy steps \
    --eval_steps 100 \
    --num_train_epochs 3 \
    --report_to tensorboard
```

**å…³é”®å‚æ•°è¯´æ˜**:
- `--sft_model_path`: SFT é˜¶æ®µè®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
- `--reward_model_path`: RM é˜¶æ®µè®­ç»ƒå¥½çš„å¥–åŠ±æ¨¡å‹è·¯å¾„
- `--total_episodes`: PPO è®­ç»ƒçš„æ€»å›åˆæ•°

**è¾“å‡º**: `outputs-ppo-qwen-v1` ç›®å½•ä¸‹çš„æœ€ç»ˆæ¨¡å‹

---

### 4.5 é˜¶æ®µä¸‰æ›¿ä»£æ–¹æ¡ˆï¼šDPOè®­ç»ƒ

**ç›®çš„**: ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæ— éœ€å¥–åŠ±æ¨¡å‹ï¼ˆæ¨èï¼Œæ›´ç®€å•é«˜æ•ˆï¼‰

**æ•°æ®**: åŒ RM é˜¶æ®µï¼Œéœ€è¦åå¥½æ•°æ®

**è®­ç»ƒå‘½ä»¤**:

```bash
CUDA_VISIBLE_DEVICES=0,1 python dpo_training.py \
    --model_name_or_path outputs-sft-qwen-v1/checkpoint-500 \
    --template_name qwen \
    --train_file_dir ./data/reward \
    --validation_file_dir ./data/reward \
    --per_device_train_batch_size 4 \
    --gradient_accumulation_steps 8 \
    --per_device_eval_batch_size 1 \
    --do_train \
    --do_eval \
    --use_peft True \
    --max_train_samples 1000 \
    --max_eval_samples 10 \
    --max_steps 100 \
    --eval_steps 20 \
    --save_steps 50 \
    --max_source_length 1024 \
    --max_target_length 512 \
    --output_dir outputs-dpo-qwen-v1 \
    --target_modules all \
    --lora_rank 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --torch_dtype bfloat16 \
    --bf16 True \
    --fp16 False \
    --device_map auto \
    --report_to tensorboard \
    --remove_unused_columns False \
    --gradient_checkpointing True \
    --cache_dir ./cache
```

**å…³é”®å‚æ•°è¯´æ˜**:
- `--model_name_or_path`: ä½¿ç”¨ SFT é˜¶æ®µè®­ç»ƒå¥½çš„æ¨¡å‹
- DPO æ— éœ€å•ç‹¬çš„å¥–åŠ±æ¨¡å‹ï¼Œç›´æ¥ä¼˜åŒ–åå¥½

**è¾“å‡º**: `outputs-dpo-qwen-v1` ç›®å½•ä¸‹çš„ DPO æ¨¡å‹

**ä¼˜åŠ¿**: 
- æ¯” RLHF æµç¨‹æ›´ç®€å•ï¼Œæ— éœ€è®­ç»ƒå¥–åŠ±æ¨¡å‹
- è®­ç»ƒæ›´ç¨³å®šï¼Œæ•ˆæœé€šå¸¸æ›´å¥½
- è®¡ç®—èµ„æºéœ€æ±‚æ›´å°‘

---

### 4.6 é˜¶æ®µä¸‰æ›¿ä»£æ–¹æ¡ˆï¼šORPOè®­ç»ƒ

**ç›®çš„**: æ¯”å€¼æ¯”åå¥½ä¼˜åŒ–ï¼Œä¸éœ€è¦å‚è€ƒæ¨¡å‹ï¼ˆæœ€æ–°æ–¹æ³•ï¼‰

**è®­ç»ƒå‘½ä»¤**:

```bash
# å‚è€ƒ run_orpo.sh
CUDA_VISIBLE_DEVICES=0,1 python orpo_training.py \
    --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --template_name qwen \
    --train_file_dir ./data/reward \
    --validation_file_dir ./data/reward \
    --per_device_train_batch_size 4 \
    --gradient_accumulation_steps 8 \
    --per_device_eval_batch_size 1 \
    --do_train \
    --do_eval \
    --use_peft True \
    --max_train_samples 1000 \
    --max_eval_samples 10 \
    --max_steps 100 \
    --eval_steps 20 \
    --save_steps 50 \
    --max_source_length 1024 \
    --max_target_length 512 \
    --output_dir outputs-orpo-qwen-v1 \
    --target_modules all \
    --lora_rank 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --torch_dtype bfloat16 \
    --bf16 True \
    --device_map auto \
    --report_to tensorboard \
    --gradient_checkpointing True \
    --cache_dir ./cache
```

**ä¼˜åŠ¿**:
- ä¸éœ€è¦å‚è€ƒæ¨¡å‹ï¼ˆref_modelï¼‰
- å¯ä»¥åŒæ—¶è¿›è¡Œ SFT å’Œå¯¹é½è®­ç»ƒ
- ç¼“è§£ç¾éš¾æ€§é—å¿˜é—®é¢˜

---

## 5. æ¨¡å‹æ¨ç†

### 5.1 åŸºæœ¬æ¨ç†

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --base_model Qwen/Qwen2.5-0.5B-Instruct \
    --lora_model outputs-sft-qwen-v1/checkpoint-500 \
    --interactive
```

**å‚æ•°è¯´æ˜**:
- `--base_model`: åŸºç¡€æ¨¡å‹è·¯å¾„
- `--lora_model`: LoRA æƒé‡è·¯å¾„ï¼ˆå¦‚æœå·²åˆå¹¶ï¼Œå¯ä¸æŒ‡å®šï¼‰
- `--interactive`: äº¤äº’å¼å¯¹è¯æ¨¡å¼
- `--template_name`: å¯¹è¯æ¨¡æ¿åç§°

### 5.2 æ‰¹é‡æ¨ç†

```bash
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --base_model Qwen/Qwen2.5-0.5B-Instruct \
    --lora_model outputs-sft-qwen-v1/checkpoint-500 \
    --data_file input.jsonl \
    --output_file output.jsonl \
    --template_name qwen
```

### 5.3 åˆå¹¶ LoRA æƒé‡ï¼ˆå¯é€‰ï¼‰

å¦‚æœå¸Œæœ›éƒ¨ç½²åˆå¹¶åçš„æ¨¡å‹ï¼š

```bash
python merge_peft_adapter.py \
    --base_model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --peft_model_path outputs-sft-qwen-v1/checkpoint-500 \
    --output_dir merged-sft-qwen-v1
```

åˆå¹¶åå¯ç›´æ¥ä½¿ç”¨åˆå¹¶åçš„æ¨¡å‹è·¯å¾„ï¼Œæ— éœ€æŒ‡å®š `--lora_model`ã€‚

---

## 6. æ¨¡å‹éƒ¨ç½²

### 6.1 Gradio Web ç•Œé¢

å¯åŠ¨ Web ç•Œé¢è¿›è¡Œäº¤äº’å¼å¯¹è¯ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python gradio_demo.py \
    --base_model Qwen/Qwen2.5-0.5B-Instruct \
    --lora_model outputs-sft-qwen-v1/checkpoint-500 \
    --template_name qwen
```

è®¿é—® `http://localhost:7860` å³å¯ä½¿ç”¨ Web ç•Œé¢ã€‚

### 6.2 FastAPI æœåŠ¡

å¯åŠ¨ API æœåŠ¡ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python fastapi_server_demo.py \
    --base_model Qwen/Qwen2.5-0.5B-Instruct \
    --lora_model outputs-sft-qwen-v1/checkpoint-500 \
    --template_name qwen
```

### 6.3 vLLM éƒ¨ç½²ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰

ä½¿ç”¨ vLLM è¿›è¡Œé«˜æ€§èƒ½éƒ¨ç½²ï¼š

```bash
sh vllm_deployment.sh
```

æˆ–æ‰‹åŠ¨é…ç½®ï¼š

```bash
python -m vllm.entrypoints.openai.api_server \
    --model merged-sft-qwen-v1 \
    --tensor-parallel-size 1 \
    --port 8000
```

---

## 7. å¸¸è§é—®é¢˜

### 7.1 æ˜¾å­˜ä¸è¶³ (OOM)

**é—®é¢˜**: `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å° `--per_device_train_batch_size`
2. å¢å¤§ `--gradient_accumulation_steps`ï¼ˆä¿æŒæœ‰æ•ˆ batch size ä¸å˜ï¼‰
3. ä½¿ç”¨ QLoRA 4bit é‡åŒ–ï¼š
   ```bash
   pip install bitsandbytes
   # åœ¨è„šæœ¬ä¸­æ·»åŠ é‡åŒ–é…ç½®
   ```
4. å¯ç”¨ `--gradient_checkpointing`ï¼ˆå·²é»˜è®¤å¯ç”¨ï¼‰
5. å‡å° `--model_max_length` æˆ– `--block_size`

### 7.2 è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
1. å¯ç”¨ Flash Attention: `--flash_attn True`
2. ä½¿ç”¨ bfloat16: `--bf16 --torch_dtype bfloat16`
3. å¢åŠ  `--preprocessing_num_workers`
4. ä½¿ç”¨å¤šå¡è®­ç»ƒï¼ˆtorchrunï¼‰
5. æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æˆä¸ºç“¶é¢ˆ

### 7.3 æ•°æ®æ ¼å¼é”™è¯¯

**é—®é¢˜**: `KeyError` æˆ–æ•°æ®åŠ è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦ç¬¦åˆæ¨¡æ¿è¦æ±‚
2. éªŒè¯ JSONL æ–‡ä»¶æ ¼å¼æ­£ç¡®æ€§ï¼š
   ```bash
   python validate_jsonl.py your_data.jsonl
   ```
3. ç¡®è®¤ `--template_name` ä¸æ•°æ®æ ¼å¼åŒ¹é…

### 7.4 æ¨¡å‹ç”Ÿæˆè´¨é‡å·®

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ è®­ç»ƒæ•°æ®é‡å’Œè´¨é‡
2. è°ƒæ•´å­¦ä¹ ç‡ï¼ˆé€šå¸¸ SFT ä½¿ç”¨ 1e-5 åˆ° 5e-5ï¼‰
3. å¢åŠ è®­ç»ƒè½®æ•°ï¼ˆæ³¨æ„è¿‡æ‹Ÿåˆï¼‰
4. ä½¿ç”¨ DPO/ORPO è¿›è¡Œåå¥½å¯¹é½
5. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®

### 7.5 å¤šå¡è®­ç»ƒå¤±è´¥

**é—®é¢˜**: DDP è®­ç»ƒæŠ¥é”™

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿ä½¿ç”¨ `torchrun` è€Œä¸æ˜¯ `python`
2. æ£€æŸ¥ `CUDA_VISIBLE_DEVICES` è®¾ç½®
3. å¢åŠ  `--ddp_timeout` å€¼
4. æŸäº›è„šæœ¬ï¼ˆå¦‚ reward_modeling.pyï¼‰ä¸æ”¯æŒå¤šå¡ï¼Œä½¿ç”¨å•å¡

---

## 8. èµ„æºéœ€æ±‚

### 8.1 æ˜¾å­˜éœ€æ±‚å‚è€ƒè¡¨

| è®­ç»ƒæ–¹æ³• | ç²¾åº¦ | 7Bæ¨¡å‹ | 13Bæ¨¡å‹ | 70Bæ¨¡å‹ |
|---------|------|--------|---------|---------|
| å…¨å‚æ•° | AMP | 120GB | 240GB | 1200GB |
| å…¨å‚æ•° | 16bit | 60GB | 120GB | 600GB |
| LoRA | 16bit | 16GB | 32GB | 160GB |
| QLoRA | 8bit | 10GB | 20GB | 80GB |
| QLoRA | 4bit | 6GB | 12GB | 48GB |

### 8.2 è®­ç»ƒæ—¶é—´ä¼°ç®—

ä»¥ Qwen2.5-7B æ¨¡å‹ï¼Œ1000 æ¡æ•°æ®ä¸ºä¾‹ï¼š

- **PT é˜¶æ®µ**: çº¦ 1-2 å°æ—¶ï¼ˆå•å¡ A100ï¼‰
- **SFT é˜¶æ®µ**: çº¦ 30 åˆ†é’Ÿ - 1 å°æ—¶
- **DPO é˜¶æ®µ**: çº¦ 20-30 åˆ†é’Ÿ
- **PPO é˜¶æ®µ**: çº¦ 1-2 å°æ—¶

å®é™…æ—¶é—´å–å†³äºæ•°æ®é‡ã€æ¨¡å‹å¤§å°å’Œç¡¬ä»¶é…ç½®ã€‚

---

## 9. è®­ç»ƒæµç¨‹ç¤ºä¾‹

### å®Œæ•´æµç¨‹ï¼šPT â†’ SFT â†’ DPO

```bash
# 1. å¢é‡é¢„è®­ç»ƒ
sh run_pt.sh

# 2. åˆå¹¶ PT æƒé‡ï¼ˆå¯é€‰ï¼‰
python merge_peft_adapter.py \
    --base_model_name_or_path Qwen/Qwen2.5-0.5B \
    --peft_model_path outputs-pt-qwen-v1/checkpoint-500 \
    --output_dir merged-pt-qwen-v1

# 3. æœ‰ç›‘ç£å¾®è°ƒ
# ä¿®æ”¹ run_sft.sh ä¸­çš„ model_name_or_path ä¸º merged-pt-qwen-v1
sh run_sft.sh

# 4. DPO è®­ç»ƒ
sh run_dpo.sh

# 5. åˆå¹¶æœ€ç»ˆæ¨¡å‹
python merge_peft_adapter.py \
    --base_model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \
    --peft_model_path outputs-dpo-qwen-v1/checkpoint-100 \
    --output_dir merged-final-qwen-v1

# 6. æ¨ç†æµ‹è¯•
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --base_model merged-final-qwen-v1 \
    --interactive
```

### ç®€åŒ–æµç¨‹ï¼šSFT â†’ DPOï¼ˆæ¨èå¿«é€Ÿä¸Šæ‰‹ï¼‰

```bash
# 1. æœ‰ç›‘ç£å¾®è°ƒ
sh run_sft.sh

# 2. DPO è®­ç»ƒ
sh run_dpo.sh

# 3. æ¨ç†æµ‹è¯•
CUDA_VISIBLE_DEVICES=0 python inference.py \
    --base_model Qwen/Qwen2.5-0.5B-Instruct \
    --lora_model outputs-dpo-qwen-v1/checkpoint-100 \
    --interactive
```

---

## 10. è¿›é˜¶æŠ€å·§

### 10.1 ä½¿ç”¨ TensorBoard ç›‘æ§è®­ç»ƒ

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir outputs-sft-qwen-v1/runs

# è®¿é—® http://localhost:6006 æŸ¥çœ‹è®­ç»ƒæ›²çº¿
```

### 10.2 æ‰©å……é¢†åŸŸè¯è¡¨

å¦‚æœæœ‰ç‰¹æ®Šé¢†åŸŸçš„è¯æ±‡ï¼Œå¯ä»¥æ‰©å……è¯è¡¨ï¼š

```bash
python build_domain_tokenizer.py \
    --base_tokenizer_path Qwen/Qwen2.5-0.5B-Instruct \
    --domain_file_path ./data/vocab/medical_vocab.txt \
    --output_dir ./tokenizer-extended
```

### 10.3 æ•°æ®è½¬æ¢

å¦‚æœéœ€è¦è½¬æ¢æ•°æ®æ ¼å¼ï¼š

```bash
python convert_dataset.py \
    --input_file your_data.json \
    --output_file converted_data.jsonl \
    --template_name qwen
```

---

## 11. å‚è€ƒæ–‡çŒ®

- [Direct Preference Optimization è®ºæ–‡](https://arxiv.org/pdf/2305.18290.pdf)
- [ORPO è®ºæ–‡](https://arxiv.org/abs/2403.07691)
- [RLHF è®­ç»ƒæµç¨‹](https://karpathy.ai/stateofgpt.pdf)
- [é¡¹ç›® Wiki](https://github.com/shibing624/MedicalGPT/wiki)

---

## 12. è·å–å¸®åŠ©

- **Issues**: [GitHub Issues](https://github.com/shibing624/MedicalGPT/issues)
- **Wiki**: [é¡¹ç›® Wiki](https://github.com/shibing624/MedicalGPT/wiki)
- **é‚®ä»¶**: xuming624@qq.com

---

## é™„å½•ï¼šå¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# ç¯å¢ƒå®‰è£…
pip install -r requirements.txt --upgrade

# è®­ç»ƒ
sh run_sft.sh      # æœ‰ç›‘ç£å¾®è°ƒ
sh run_dpo.sh      # DPO è®­ç»ƒ
sh run_orpo.sh     # ORPO è®­ç»ƒ
sh run_pt.sh       # å¢é‡é¢„è®­ç»ƒ
sh run_rm.sh       # å¥–åŠ±å»ºæ¨¡
sh run_ppo.sh      # PPO å¼ºåŒ–å­¦ä¹ 

# æ¨ç†
python inference.py --base_model MODEL --lora_model LORA --interactive
python gradio_demo.py --base_model MODEL --lora_model LORA

# å·¥å…·
python merge_peft_adapter.py  # åˆå¹¶ LoRA æƒé‡
python validate_jsonl.py      # éªŒè¯æ•°æ®æ ¼å¼
python convert_dataset.py     # è½¬æ¢æ•°æ®æ ¼å¼
```

---

**ç¥æ‚¨è®­ç»ƒé¡ºåˆ©ï¼å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿æäº¤ Issue æˆ–æŸ¥é˜…é¡¹ç›® Wikiã€‚**

